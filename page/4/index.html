<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">
<meta name="google-site-verification" content="nPT3ONUGntVHfQCZH2D5GcUMgg5DH4IReN4GIs0GrW8" />








<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="好记性不如烂笔头！">
<meta property="og:type" content="website">
<meta property="og:title" content="wForget&#39;s blog">
<meta property="og:url" content="https://wforget.github.io/page/4/index.html">
<meta property="og:site_name" content="wForget&#39;s blog">
<meta property="og:description" content="好记性不如烂笔头！">
<meta property="og:locale">
<meta property="article:author" content="wangz">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://wforget.github.io/page/4/"/>





  <title>wForget's blog</title>
  








<meta name="generator" content="Hexo 6.3.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">wForget's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wforget.github.io/2018/10/16/Kafka%E6%A6%82%E8%BF%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wForget's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/16/Kafka%E6%A6%82%E8%BF%B0/" itemprop="url">Kafka概述</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-16T15:30:41+08:00">
                2018-10-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><ul>
<li>构造实时流数据管道，它可以在系统或应用之间可靠地获取数据。(相当于message queue)</li>
<li>构建实时流式应用程序，对这些流数据进行转换或者影响。 (就是流处理，通过kafka stream topic和topic之间内部进行变化)</li>
</ul>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><ul>
<li>Kafka 作为一个集群，运行在一台或者多台服务器上.</li>
<li>Kafka 通过 topic 对存储的流数据进行分类。</li>
<li>每条记录中包含一个key，一个value和一个timestamp。</li>
</ul>
<h3 id="四个核心API"><a href="#四个核心API" class="headerlink" title="四个核心API"></a>四个核心API</h3><ul>
<li>Producer API 允许一个应用程序发布一串流式的数据到一个或者多个Kafka topic。</li>
<li>Consumer API 允许一个应用程序订阅一个或多个 topic ，并且对发布给他们的流式数据进行处理。</li>
<li>Streams API 允许一个应用程序作为一个流处理器，消费一个或者多个topic产生的输入流，然后生产一个输出流到一个或多个topic中去，在输入输出流中进行有效的转换。</li>
<li>Connector API 允许构建并运行可重用的生产者或者消费者，将Kafka topics连接到已存在的应用程序或者数据系统。比如，连接到一个关系型数据库，捕捉表（table）的所有变更内容。</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wforget.github.io/2018/10/12/Tomcat%E9%85%8D%E7%BD%AEAPR%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wForget's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/12/Tomcat%E9%85%8D%E7%BD%AEAPR%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/" itemprop="url">Tomcat配置APR运行模式</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-12T11:19:57+08:00">
                2018-10-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Tomcat三种运行模式"><a href="#Tomcat三种运行模式" class="headerlink" title="Tomcat三种运行模式"></a>Tomcat三种运行模式</h2><blockquote>
<p>BIO(blocking I&#x2F;O)</p>
</blockquote>
<p>阻塞式I&#x2F;O操作，表示Tomcat使用的是传统的Java I&#x2F;O操作(即java.io包及其子包)，对于每一个请求都要创建一个线程来进行处理，所以开销较大不适合处理高并发的场景。</p>
<blockquote>
<p>NIO(New IO)</p>
</blockquote>
<p>基于java中非阻塞IO操作的API实现(即java.nio包及其子包)，比传统的i&#x2F;o处理方式有更高的并发运行性能。</p>
<blockquote>
<p>APR(Apache Portable Runtime&#x2F;Apache可移植运行库)</p>
</blockquote>
<p>Apache Portable Runtime是Apache HTTP服务器的支持库。可以简单地理解为，Tomcat将以JNI的形式调用Apache HTTP服务器的核心动态链接库来处理文件读取或网络传输操作，从而大大地提高Tomcat对静态文件的处理性能。 Tomcat apr也是在Tomcat上运行高并发应用的首选模式。</p>
<h2 id="安装APR"><a href="#安装APR" class="headerlink" title="安装APR"></a>安装APR</h2><blockquote>
<p>安装gcc</p>
</blockquote>
<p>查看gcc是否安装，gcc –version，没有安装的话进行安装</p>
<blockquote>
<p>下载tomcat、apr、apr-util、openssl</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-7/v7.0.72/bin/apache-tomcat-7.0.72.tar.gz</span><br><span class="line">wget http://mirrors.tuna.tsinghua.edu.cn/apache/apr/apr-1.5.2.tar.gz</span><br><span class="line">wget http://mirrors.tuna.tsinghua.edu.cn/apache/apr/apr-util-1.5.4.tar.gz</span><br><span class="line"></span><br><span class="line">wget https://www.openssl.org/source/openssl-1.0.2k.tar.gz</span><br></pre></td></tr></table></figure>

<blockquote>
<p>编译apr</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir /usr/local/apr</span><br><span class="line">sudo chown hadoop:hadoop /usr/local/apr</span><br><span class="line">cd apr-1.5.2</span><br><span class="line">./configure &amp;&amp; make &amp;&amp; make install</span><br></pre></td></tr></table></figure>

<blockquote>
<p>编译apr-util</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd apr-util-1.5.4</span><br><span class="line">./configure --with-apr=/usr/local/apr/ &amp;&amp; make &amp;&amp; make install</span><br></pre></td></tr></table></figure>

<blockquote>
<p>编译openssl</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir /usr/local/ssl</span><br><span class="line">sudo chown hadoop:hadoop /usr/local/ssl</span><br><span class="line">./config  -fPIC no-gost no-shared no-zlib &amp;&amp; make &amp;&amp; make install</span><br></pre></td></tr></table></figure>

<blockquote>
<p>编译tomcat-native</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd apache-tomcat-7.0.70/bin/</span><br><span class="line">tar xzvf tomcat-native.tar.gz</span><br><span class="line">cd tomcat-native-1.2.7-src/native/</span><br><span class="line">./configure CFLAGS=-fPIC --with-apr=/usr/local/apr/ --with-java-home=/usr/java/jdk1.8.0_131  --with-ssl=/usr/local/ssl &amp;&amp; make install</span><br></pre></td></tr></table></figure>

<h2 id="配置Tomcat使用APR运行模式"><a href="#配置Tomcat使用APR运行模式" class="headerlink" title="配置Tomcat使用APR运行模式"></a>配置Tomcat使用APR运行模式</h2><blockquote>
<p>修改apache-tomcat-7.0.70&#x2F;bin&#x2F;catalina.sh文件</p>
</blockquote>
<p>添加CATALINA_OPTS&#x3D;”$CATALINA_OPTS -Djava.library.path&#x3D;&#x2F;usr&#x2F;local&#x2F;apr&#x2F;lib”</p>
<blockquote>
<p>修改apache-tomcat-7.0.70&#x2F;conf&#x2F;server.xml 文件</p>
</blockquote>
<p>将protocol由HTTP&#x2F;1.1 改成 org.apache.coyote.http11.Http11AprProtocol</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;Connector port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11AprProtocol&quot;</span><br><span class="line">		   connectionTimeout=&quot;20000&quot;</span><br><span class="line">		   redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>修改内存(apache-tomcat-7.0.70&#x2F;bin&#x2F;catalina.sh)</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS=&quot;-server -Xmx8g -Xms8g -Xss256k -XX:+DisableExplicitGC -XX:LargePageSizeInBytes=128m -XX:+UseFastAccessorMethods -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:InitiatingHeapOccupancyPercent=50 -XX:G1ReservePercent=15&quot;</span><br></pre></td></tr></table></figure>

<h2 id="压测"><a href="#压测" class="headerlink" title="压测"></a>压测</h2><p>使用apache ab压测</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ab -kc 1000 -n 10000 http://localhost/</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wforget.github.io/2018/10/09/Kafka%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wForget's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/09/Kafka%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" itemprop="url">Kafka常用命令</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-09T17:28:44+08:00">
                2018-10-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Kafka常用命令"><a href="#Kafka常用命令" class="headerlink" title="Kafka常用命令"></a>Kafka常用命令</h2><blockquote>
<p>启动命令</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-server-start.sh  config/server.properties</span><br><span class="line"></span><br><span class="line">#后台启动</span><br><span class="line">bin/kafka-server-start.sh -daemon config/server.properties</span><br><span class="line">bin/kafka-server-start.sh config/server.properties 1&gt;/dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>创建topic</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 2 --partitions 10 --topic testTopic</span><br></pre></td></tr></table></figure>

<blockquote>
<p>查看所有的topic</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --list --zookeeper 127.0.0.1:2181</span><br></pre></td></tr></table></figure>

<blockquote>
<p>查看topic的详细信息</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --describe --topic testTopic</span><br></pre></td></tr></table></figure>

<blockquote>
<p>为topic增加partition</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --alter --partitions 20 --topic testTopic</span><br></pre></td></tr></table></figure>

<blockquote>
<p>删除topic</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --delete --zookeeper 127.0.0.1:2181 --topic testTopic  #要配置允许删除topic，delete.topic.enable=true</span><br></pre></td></tr></table></figure>

<blockquote>
<p>kafka生产者客户端命令</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-producer.sh --broker-list localhost:9092 --topic testTopic</span><br><span class="line">bin/kafka-console-producer.sh --broker-list localhost:9092 --topic testTopic --producer.config config/producer.properties</span><br></pre></td></tr></table></figure>

<blockquote>
<p>kafka消费者客户端命令</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic testTopic</span><br><span class="line">bin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic testTopic --consumer.config config/consumer.properties</span><br></pre></td></tr></table></figure>

<blockquote>
<p>新消费者列表查询（支持0.9版本+）</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --list</span><br></pre></td></tr></table></figure>

<blockquote>
<p>显示某个消费组的消费详情（支持0.9版本+）</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --describe --group testGroup001</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wforget.github.io/2018/10/09/Kafka-Stream-TimestampExtractor/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wForget's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/09/Kafka-Stream-TimestampExtractor/" itemprop="url">Kafka Stream TimestampExtractor</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-09T16:42:26+08:00">
                2018-10-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>线上的KafkaStream程序出现了下面的异常，”has invalid (negative) timestamp.”：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread &quot;ad-effect-application-001-bf034f5b-9012-4e5e-aab3-128774768e74-StreamThread-2&quot; org.apache.kafka.streams.errors.StreamsException: Input record ConsumerRecord(topic = dmpRawLog7, partition = 5, offset = 375653352, CreateTime = -1, serialized key size = -1, serialized value size = 980, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = &#123;&quot;data&quot;:&quot;&#123;\&quot;type\&quot;:\&quot;getad\&quot;,\&quot;sid\&quot;:\&quot;e52db2495177bd3c\&quot;,\&quot;time\&quot;:1538208879,\&quot;zone\&quot;:&#123;\&quot;id\&quot;:\&quot;1xsgiwb0jqfh\&quot;,\&quot;resourceid\&quot;:\&quot;\&quot;,\&quot;agentid\&quot;:\&quot;1xsgh2et8jk7\&quot;,\&quot;businessid\&quot;:\&quot;sndo_sndo\&quot;&#125;,\&quot;user\&quot;:&#123;\&quot;id\&quot;:\&quot;5d4073746afabbf9a11a27fbf9fe33eb\&quot;,\&quot;clkip\&quot;:\&quot;\&quot;,\&quot;clkuseragent\&quot;:\&quot;\&quot;,\&quot;clkvalid\&quot;:0&#125;,\&quot;scenario\&quot;:&#123;\&quot;page\&quot;:\&quot;http://sp360.9idudu.com/sdk/defaultr/app/share/share.html?appId=9214af24213ab9212c5235fafe82c4d4\&quot;,\&quot;referrer\&quot;:\&quot;http://sp360.9idudu.com/sdk/defaultr/app/share/share.html?appId=9214af24213ab9212c5235fafe82c4d4\\u0026appSecret=a943ff9a630c3c01c3e92444f354f860\\u0026messageId=cmsqukngt1irs\\u0026messageType=NEWS\\u0026parentId=af274d7b4026bcff1c04131321eaf7ec\&quot;&#125;,\&quot;device\&quot;:&#123;\&quot;ip\&quot;:\&quot;171.220.55.140\&quot;,\&quot;agent\&quot;:\&quot;Mozilla/5.0 (Linux; Android 7.1.2; KINGSUN-F16 Build/N2G47H; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/52.0.2743.100 Mobile Safari/537.36 Imei/434766830973068DCBEA8AFB32463F5F\&quot;,\&quot;screen\&quot;:\&quot;\&quot;&#125;,\&quot;fill\&quot;:1,\&quot;appid\&quot;:\&quot;\&quot;&#125;&quot;&#125;) has invalid (negative) timestamp. Possibly because a pre-0.10 producer client was used to write this record to Kafka without embedding a timestamp, or because the input topic was created before upgrading the Kafka cluster to 0.10+. Use a different TimestampExtractor to process this data.</span><br><span class="line">        at org.apache.kafka.streams.processor.FailOnInvalidTimestamp.onInvalidTimestamp(FailOnInvalidTimestamp.java:63)</span><br><span class="line">        at org.apache.kafka.streams.processor.ExtractRecordMetadataTimestamp.extract(ExtractRecordMetadataTimestamp.java:61)</span><br><span class="line">        at org.apache.kafka.streams.processor.FailOnInvalidTimestamp.extract(FailOnInvalidTimestamp.java:46)</span><br><span class="line">        at org.apache.kafka.streams.processor.internals.RecordQueue.addRawRecords(RecordQueue.java:85)</span><br><span class="line">        at org.apache.kafka.streams.processor.internals.PartitionGroup.addRawRecords(PartitionGroup.java:117)</span><br><span class="line">        at org.apache.kafka.streams.processor.internals.StreamTask.addRecords(StreamTask.java:493)</span><br><span class="line">        at org.apache.kafka.streams.processor.internals.StreamThread.addRecordsToTasks(StreamThread.java:628)</span><br><span class="line">        at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:512)</span><br><span class="line">        at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:482)</span><br><span class="line">        at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:459)</span><br></pre></td></tr></table></figure>

<h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>查阅资料发现是时间戳导致的，kafka中我存的是一个Json字符串，里面包含timestamp字段，出问题的数据是因为没有timestamp字段，所以自己实现TimestampExtractor。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line">import org.apache.kafka.streams.processor.TimestampExtractor;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * Created by hadoop on 2018/9/30.</span><br><span class="line"> */</span><br><span class="line">public class CurrentTimestampExtractor implements TimestampExtractor &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public long extract(ConsumerRecord&lt;Object, Object&gt; record, long previousTimestamp) &#123;</span><br><span class="line">        long timestamp = record.timestamp();</span><br><span class="line">        if (timestamp &lt; 0) &#123;</span><br><span class="line">            return System.currentTimeMillis();</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            return timestamp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Kafka Stream 配置自定义的TimestampExtractor：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafkaStreamConf.put(StreamsConfig.DEFAULT_TIMESTAMP_EXTRACTOR_CLASS_CONFIG, CurrentTimestampExtractor.class.getName());</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wforget.github.io/2018/10/09/Kafka-Stream-WordCount/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wForget's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/09/Kafka-Stream-WordCount/" itemprop="url">Kafka Stream WordCount</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-09T16:31:35+08:00">
                2018-10-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Kafka-Stream-示例"><a href="#Kafka-Stream-示例" class="headerlink" title="Kafka Stream 示例"></a>Kafka Stream 示例</h2><blockquote>
<p>Maven依赖</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">	&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;</span><br><span class="line">	&lt;artifactId&gt;kafka-streams&lt;/artifactId&gt;</span><br><span class="line">	&lt;version&gt;0.11.0.2&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>WordCount Demo</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">public class WordCountApplication &#123;</span><br><span class="line"> </span><br><span class="line">    public static void main(final String[] args) throws Exception &#123;</span><br><span class="line">        Properties props = new Properties();</span><br><span class="line">        props.put(StreamsConfig.APPLICATION_ID_CONFIG, &quot;wordcount-application&quot;);</span><br><span class="line">        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;kafka-broker1:9092&quot;);</span><br><span class="line">        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());</span><br><span class="line">        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());</span><br><span class="line"> </span><br><span class="line">        StreamsBuilder builder = new StreamsBuilder();</span><br><span class="line">        KStream&lt;String, String&gt; textLines = builder.stream(&quot;TextLinesTopic&quot;);</span><br><span class="line">        KTable&lt;String, Long&gt; wordCounts = textLines</span><br><span class="line">            .flatMapValues(textLine -&gt; Arrays.asList(textLine.toLowerCase().split(&quot;\\W+&quot;)))</span><br><span class="line">            .groupBy((key, word) -&gt; word)</span><br><span class="line">            .count(Materialized.&lt;String, Long, KeyValueStore&lt;Bytes, byte[]&gt;&gt;as(&quot;counts-store&quot;));</span><br><span class="line">        wordCounts.toStream().to(&quot;WordsWithCountsTopic&quot;, Produced.with(Serdes.String(), Serdes.Long()));</span><br><span class="line"> </span><br><span class="line">        KafkaStreams streams = new KafkaStreams(builder.build(), props);</span><br><span class="line">        streams.start();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>KafkaStream 一些配置说明</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Properties props = new Properties();</span><br><span class="line">props.put(StreamsConfig.APPLICATION_ID_CONFIG, &quot;wordcount-application&quot;);	//KafkaStream Application Id</span><br><span class="line">props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;kafka-broker1:9092&quot;);	//kafka bootstrap servers</span><br><span class="line">props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());	//key Serde</span><br><span class="line">props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());	//value Serde</span><br><span class="line"></span><br><span class="line">props.put(StreamsConfig.consumerPrefix(ConsumerConfig.MAX_POLL_RECORDS_CONFIG), 1000);	//一次poll操作获取的最大记录数</span><br><span class="line"></span><br><span class="line">props.put(StreamsConfig.consumerPrefix(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG), &quot;latest&quot;);	//如果是新的group latest 表示从当前最新开始消费，默认是earliest</span><br><span class="line"></span><br><span class="line">props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 10);		//stream操作的线程数</span><br><span class="line"></span><br><span class="line">props.put(StreamsConfig.consumerPrefix(ConsumerConfig.EXCLUDE_INTERNAL_TOPICS_CONFIG), false);		//是否排除内部的topics，比如记录offset的topic：__consumer_offsets</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wforget.github.io/2018/10/09/%E3%80%8AFlume%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0%E3%80%8B-%E5%85%AD%E3%80%81%E8%87%AA%E5%AE%9A%E4%B9%89Flume%E6%8F%92%E4%BB%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wForget's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/09/%E3%80%8AFlume%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0%E3%80%8B-%E5%85%AD%E3%80%81%E8%87%AA%E5%AE%9A%E4%B9%89Flume%E6%8F%92%E4%BB%B6/" itemprop="url">《Flume系列文章》 六、自定义Flume插件</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-09T10:36:16+08:00">
                2018-10-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="自定义Flume插件"><a href="#自定义Flume插件" class="headerlink" title="自定义Flume插件"></a>自定义Flume插件</h2><p>Flume的很多组件都是可以使用自定义的组件，可以自己实现Source、Channel、Sink，也可以编写Channel Selectors、Sink Processors、Interceptors、Monitoring等。每个组件的实现都是继承组件定义的接口，实现相关的方法，具体的实现可以参考Flume已经写好的组件。</p>
<blockquote>
<p>创建插件项目，继承组件的接口并实现相关方法</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public class DmpMemoryChannel extends BasicChannelSemantics &#123;</span><br><span class="line">	// TODO</span><br><span class="line">	// 在编写插件的时候可以通过context获取配置文件中的配置，可以自定义一些配置。</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>打Jar包，并放入到 plugins.d 目录中</p>
</blockquote>
<p>在plugins.d中创建dmp-flume-plugin&#x2F;lib、dmp-flume-plugin&#x2F;libext、dmp-flume-plugin&#x2F;native目录，lib中放插件的Jar包，libext中放插件依赖的Jar包，native存放any required native libraries, such as .so files。</p>
<blockquote>
<p>配置组件</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">agent.channels.memoryChannel1.type = org.sndo.dmp.flume.channel.memory.DmpMemoryChannel</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wforget.github.io/2018/09/28/Druid%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wForget's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/28/Druid%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/" itemprop="url">Druid集群搭建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-28T10:59:58+08:00">
                2018-09-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="下载解压安装包"><a href="#下载解压安装包" class="headerlink" title="下载解压安装包"></a>下载解压安装包</h2><p>下载Druid包，解压到安装目录：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://static.druid.io/artifacts/releases/druid-0.12.3-bin.tar.gz</span><br></pre></td></tr></table></figure>

<p>下载MySQL metadata store extension，并解压到extensions目录中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://static.druid.io/artifacts/releases/mysql-metadata-storage-0.12.3.tar.gz</span><br></pre></td></tr></table></figure>

<p>手动创建 druid-0.12.3&#x2F;var&#x2F;tmp 和 druid-0.12.3&#x2F;var&#x2F;hadoop-tmp 目录</p>
<h2 id="创建Metadata-storage和Deep-storage"><a href="#创建Metadata-storage和Deep-storage" class="headerlink" title="创建Metadata storage和Deep storage"></a>创建Metadata storage和Deep storage</h2><blockquote>
<p>Metadata storage</p>
</blockquote>
<p>我使用的是MySql数据库作为元数据库，在MySql中创建一个Druid用户和Druid数据库，并给Druid用户配置Druid数据库的所有权限。</p>
<blockquote>
<p>Deep storage</p>
</blockquote>
<p>我使用HDFS作为Druid的Deep storage，在hdfs创建&#x2F;druid目录，相关命令如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo su hdfs</span><br><span class="line">hadoop fs -mkdir -p /druid</span><br><span class="line">hadoop fs -chown hadoop:supergroup /druid	#将目录授权给hadoop</span><br></pre></td></tr></table></figure>

<h2 id="集群分配"><a href="#集群分配" class="headerlink" title="集群分配"></a>集群分配</h2><p>线上集群一共10台机器，启动8个数据节点、2个Master节点、2个查询节点。<br>数据节点：包括 Historical 和 MiddleManager 进程。<br>Master节点：包括 Coordinator 和 Overlord 进程。<br>查询节点：包括 Broker 和 Router(可选) 进程。</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>创建druid-0.12.3&#x2F;conf-online目录，将conf&#x2F;中的配置复制到conf-online&#x2F;中，在进行修改，具体配置如下：</p>
<h3 id="Common配置"><a href="#Common配置" class="headerlink" title="Common配置"></a>Common配置</h3><p>配置文件：conf-online&#x2F;druid&#x2F;_common&#x2F;common.runtime.properties</p>
<blockquote>
<p>复制hadoop配置文件</p>
</blockquote>
<p>将Hadoop configuration XMLs(core-site.xml, hdfs-site.xml, yarn-site.xml, mapred-site.xml)复制到conf-online&#x2F;druid&#x2F;_common中。</p>
<blockquote>
<p>配置 Zookeeper</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#</span><br><span class="line"># Zookeeper</span><br><span class="line">#</span><br><span class="line"></span><br><span class="line">druid.zk.service.host=host01:2181,host02:2181,host03:2181</span><br><span class="line">druid.zk.paths.base=/druid</span><br></pre></td></tr></table></figure>

<blockquote>
<p>添加 extensions (“druid-kafka-indexing-service” “mysql-metadata-storage” “druid-hdfs-storage”)</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">druid.extensions.loadList=[&quot;druid-kafka-eight&quot;, &quot;druid-histogram&quot;, &quot;druid-datasketches&quot;, &quot;druid-lookups-cached-global&quot;, &quot;mysql-metadata-storage&quot;, &quot;druid-kafka-indexing-service&quot;, &quot;druid-hdfs-storage&quot;]</span><br></pre></td></tr></table></figure>

<blockquote>
<p>配置 Metadata storage</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#</span><br><span class="line"># Metadata storage</span><br><span class="line">#</span><br><span class="line"></span><br><span class="line"># For MySQL:</span><br><span class="line">druid.metadata.storage.type=mysql</span><br><span class="line">druid.metadata.storage.connector.connectURI=jdbc:mysql://host01:3306/druid</span><br><span class="line">druid.metadata.storage.connector.user=druid</span><br><span class="line">druid.metadata.storage.connector.password=123456</span><br></pre></td></tr></table></figure>

<blockquote>
<p>配置 Deep storage</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#</span><br><span class="line"># Deep storage</span><br><span class="line">#</span><br><span class="line"></span><br><span class="line"># For HDFS (make sure to include the HDFS extension and that your Hadoop config files in the cp):</span><br><span class="line">druid.storage.type=hdfs</span><br><span class="line">druid.storage.storageDirectory=hdfs://nameservice1/druid/segments</span><br></pre></td></tr></table></figure>

<blockquote>
<p>配置 Indexing service logs</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#</span><br><span class="line"># Indexing service logs</span><br><span class="line">#</span><br><span class="line"></span><br><span class="line"># For HDFS (make sure to include the HDFS extension and that your Hadoop config files in the cp):</span><br><span class="line">druid.indexer.logs.type=hdfs</span><br><span class="line">druid.indexer.logs.directory=hdfs://nameservice1/druid/indexing-logs</span><br></pre></td></tr></table></figure>

<blockquote>
<p>设置 Monitoring 日志级别</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#</span><br><span class="line"># Monitoring</span><br><span class="line">#</span><br><span class="line">druid.monitoring.monitors=[&quot;io.druid.java.util.metrics.JvmMonitor&quot;]</span><br><span class="line">druid.emitter=logging</span><br><span class="line">druid.emitter.logging.logLevel=info</span><br></pre></td></tr></table></figure>

<h3 id="Coordinator配置"><a href="#Coordinator配置" class="headerlink" title="Coordinator配置"></a>Coordinator配置</h3><p>配置目录：conf-online&#x2F;druid&#x2F;coordinator</p>
<blockquote>
<p>jvm.config</p>
</blockquote>
<p>修改时区</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-server</span><br><span class="line">-Xms3g</span><br><span class="line">-Xmx3g</span><br><span class="line">-Duser.timezone=UTC+0800</span><br><span class="line">-Dfile.encoding=UTF-8</span><br><span class="line">-Djava.io.tmpdir=var/tmp</span><br><span class="line">-Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager</span><br><span class="line">-Dderby.stream.error.file=var/druid/derby.log</span><br></pre></td></tr></table></figure>

<blockquote>
<p>runtime.properties</p>
</blockquote>
<p>修改host和port</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">druid.service=druid/coordinator</span><br><span class="line">druid.host=192.168.1.120</span><br><span class="line">druid.port=28081</span><br><span class="line"></span><br><span class="line">druid.coordinator.startDelay=PT30S</span><br><span class="line">druid.coordinator.period=PT30S</span><br></pre></td></tr></table></figure>

<h3 id="Overlord配置"><a href="#Overlord配置" class="headerlink" title="Overlord配置"></a>Overlord配置</h3><p>配置目录：conf-online&#x2F;druid&#x2F;overlord</p>
<blockquote>
<p>jvm.config</p>
</blockquote>
<p>修改时区</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">-server</span><br><span class="line">-Xms3g</span><br><span class="line">-Xmx3g</span><br><span class="line">-Duser.timezone=UTC+0800</span><br><span class="line">-Dfile.encoding=UTF-8</span><br><span class="line">-Djava.io.tmpdir=var/tmp</span><br><span class="line">-Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager</span><br></pre></td></tr></table></figure>

<blockquote>
<p>runtime.properties</p>
</blockquote>
<p>修改host和port</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">druid.service=druid/overlord</span><br><span class="line">druid.host=192.168.1.120</span><br><span class="line">druid.port=28090</span><br><span class="line"></span><br><span class="line">druid.indexer.queue.startDelay=PT30S</span><br><span class="line"></span><br><span class="line">druid.indexer.runner.type=remote</span><br><span class="line">druid.indexer.storage.type=metadata</span><br></pre></td></tr></table></figure>

<h3 id="Historical配置"><a href="#Historical配置" class="headerlink" title="Historical配置"></a>Historical配置</h3><p>配置目录：conf-online&#x2F;druid&#x2F;historical</p>
<blockquote>
<p>jvm.config</p>
</blockquote>
<p>修改时区和MaxDirectMemorySize</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-server</span><br><span class="line">-Xms8g</span><br><span class="line">-Xmx8g</span><br><span class="line">-XX:MaxDirectMemorySize=20g</span><br><span class="line">-Duser.timezone=UTC+0800</span><br><span class="line">-Dfile.encoding=UTF-8</span><br><span class="line">-Djava.io.tmpdir=var/tmp</span><br><span class="line">-Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager</span><br></pre></td></tr></table></figure>

<blockquote>
<p>runtime.properties</p>
</blockquote>
<p>修改host和port<br>调整druid.server.http.numThreads和druid.processing.numThreads（建议cores-1）<br>注意：MaxDirectMemorySiz &gt;&#x3D; druid.processing.buffer.sizeBytes * (druid.processing.numMergeBuffers + druid.processing.numThreads + 1)<br>druid.segmentCache.locations是本地缓存segment的地方<br>配置historical的缓存</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">druid.service=druid/historical</span><br><span class="line">druid.host=192.168.1.120</span><br><span class="line">druid.port=28083</span><br><span class="line"></span><br><span class="line"># HTTP server threads</span><br><span class="line">druid.server.http.numThreads=25</span><br><span class="line"></span><br><span class="line"># Processing threads and buffers</span><br><span class="line">druid.processing.buffer.sizeBytes=1073741824</span><br><span class="line">druid.processing.numMergeBuffers=2</span><br><span class="line">druid.processing.numThreads=15</span><br><span class="line">druid.processing.tmpDir=var/druid/processing</span><br><span class="line"></span><br><span class="line"># Segment storage</span><br><span class="line">#druid.segmentCache.locations=[&#123;&quot;path&quot;:&quot;var/druid/segment-cache&quot;,&quot;maxSize&quot;\:130000000000&#125;]</span><br><span class="line">druid.segmentCache.locations=[&#123;&quot;path&quot;:&quot;/data01/druid/segment-cache&quot;,&quot;maxSize&quot;\:100000000000&#125;, &#123;&quot;path&quot;:&quot;/data02/druid/segment-cache&quot;,&quot;maxSize&quot;\:100000000000&#125;]</span><br><span class="line">druid.server.maxSize=200000000000</span><br><span class="line"></span><br><span class="line">druid.query.groupBy.maxOnDiskStorage=10737418240</span><br><span class="line"></span><br><span class="line"># Cache</span><br><span class="line">druid.historical.cache.useCache=true</span><br><span class="line">druid.historical.cache.populateCache=true</span><br><span class="line">druid.historical.cache.unCacheable=[&quot;select&quot;]</span><br><span class="line">druid.cache.type=caffeine</span><br><span class="line">druid.cache.sizeInBytes=6000000000</span><br></pre></td></tr></table></figure>

<h3 id="MiddleManager配置"><a href="#MiddleManager配置" class="headerlink" title="MiddleManager配置"></a>MiddleManager配置</h3><p>配置目录：conf-online&#x2F;druid&#x2F;middleManager</p>
<blockquote>
<p>jvm.config</p>
</blockquote>
<p>修改时区</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-server</span><br><span class="line">-Xms64m</span><br><span class="line">-Xmx64m</span><br><span class="line">-Duser.timezone=UTC+0800</span><br><span class="line">-Dfile.encoding=UTF-8</span><br><span class="line">-Dhadoop.hadoop.tmp.dir=var/hadoop-tmp</span><br><span class="line">-Djava.io.tmpdir=var/tmp</span><br><span class="line">-Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager</span><br></pre></td></tr></table></figure>

<blockquote>
<p>runtime.properties</p>
</blockquote>
<p>修改host和port<br>修改druid.indexer.runner.javaOpts，配置MaxDirectMemorySize<br>修改druid.indexer.fork.property.druid.processing相关配置<br>指定druid.indexer.task.defaultHadoopCoordinates，HadoopIndexTasks使用的Hadoop版本</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">druid.service=druid/middleManager</span><br><span class="line">druid.host=192.168.1.120</span><br><span class="line">druid.port=28091</span><br><span class="line"></span><br><span class="line"># Number of tasks per middleManager</span><br><span class="line">druid.worker.capacity=3</span><br><span class="line"></span><br><span class="line"># Task launch parameters</span><br><span class="line">druid.indexer.runner.javaOpts=-server -Xms2g -Xmx2g -XX:MaxDirectMemorySize=4g -Duser.timezone=UTC+0800 -Dfile.encoding=UTF-8 -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager</span><br><span class="line">druid.indexer.task.baseTaskDir=var/druid/task</span><br><span class="line">druid.indexer.task.restoreTasksOnRestart=true</span><br><span class="line"></span><br><span class="line"># HTTP server threads</span><br><span class="line">druid.server.http.numThreads=25</span><br><span class="line"></span><br><span class="line"># Processing threads and buffers on Peons</span><br><span class="line">druid.indexer.fork.property.druid.processing.buffer.sizeBytes=536870912</span><br><span class="line">druid.indexer.fork.property.druid.processing.numMergeBuffers=2</span><br><span class="line">druid.indexer.fork.property.druid.processing.numThreads=2</span><br><span class="line">druid.indexer.fork.property.druid.processing.tmpDir=var/druid/processing</span><br><span class="line"></span><br><span class="line"># Hadoop indexing</span><br><span class="line">druid.indexer.task.hadoopWorkingPath=var/druid/hadoop-tmp</span><br><span class="line">druid.indexer.task.defaultHadoopCoordinates=[&quot;org.apache.hadoop:hadoop-client:2.6.0-mr1-cdh5.13.1&quot;]</span><br></pre></td></tr></table></figure>

<h3 id="Broker配置"><a href="#Broker配置" class="headerlink" title="Broker配置"></a>Broker配置</h3><p>配置目录：conf-online&#x2F;druid&#x2F;broker</p>
<blockquote>
<p>jvm.config</p>
</blockquote>
<p>修改时区<br>修改-Xms、-Xmx、MaxDirectMemorySize</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-server</span><br><span class="line">-Xms24g</span><br><span class="line">-Xmx24g</span><br><span class="line">-XX:MaxDirectMemorySize=20g</span><br><span class="line">-Duser.timezone=UTC+0800</span><br><span class="line">-Dfile.encoding=UTF-8</span><br><span class="line">-Djava.io.tmpdir=var/tmp</span><br><span class="line">-Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager</span><br></pre></td></tr></table></figure>

<blockquote>
<p>runtime.properties</p>
</blockquote>
<p>修改host和port<br>调整druid.server.http.numThreads和druid.processing.numThreads（建议cores-1）<br>注意：MaxDirectMemorySiz &gt;&#x3D; druid.processing.buffer.sizeBytes * (druid.processing.numMergeBuffers + druid.processing.numThreads + 1)<br>设置druid.sql.enable为true，可以使用sql<br>设置druid.query.groupBy.maxOnDiskStorag。合并缓冲区或dictionary填满时，将结果集溢出到磁盘的最大磁盘空间（每次查询）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">druid.service=druid/broker</span><br><span class="line">druid.host=192.168.1.120</span><br><span class="line">druid.port=28082</span><br><span class="line"></span><br><span class="line"># HTTP server threads</span><br><span class="line">druid.broker.http.numConnections=50</span><br><span class="line">druid.server.http.numThreads=40</span><br><span class="line"></span><br><span class="line"># Processing threads and buffers</span><br><span class="line">druid.processing.buffer.sizeBytes=1073741824</span><br><span class="line">druid.processing.numMergeBuffers=4</span><br><span class="line">druid.processing.numThreads=14</span><br><span class="line">druid.processing.tmpDir=var/druid/processing</span><br><span class="line"></span><br><span class="line"># SQL</span><br><span class="line">druid.sql.enable = true</span><br><span class="line"></span><br><span class="line"># Query cache</span><br><span class="line">#druid.broker.cache.useCache=true</span><br><span class="line">#druid.broker.cache.populateCache=true</span><br><span class="line">#druid.cache.type=local</span><br><span class="line">#druid.cache.sizeInBytes=2000000000</span><br><span class="line"></span><br><span class="line"># Query config</span><br><span class="line"># 查询节点请求历史节点方式，有random和connectionCount两种连接方式</span><br><span class="line">druid.broker.balancer.type=connectionCount</span><br><span class="line">druid.query.groupBy.maxOnDiskStorage=10737418240</span><br></pre></td></tr></table></figure>

<h2 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h2><blockquote>
<p>修改bin&#x2F;node.sh</p>
</blockquote>
<p>在文件前面添加 DRUID_CONF_DIR&#x3D;”conf-online&#x2F;druid”</p>
<blockquote>
<p>复制配置到其他节点上，注意要修改 host</p>
</blockquote>
<blockquote>
<p>启动 Master节点</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/coordinator.sh start</span><br><span class="line">bin/overlord.sh start</span><br></pre></td></tr></table></figure>

<blockquote>
<p>启动 Data节点</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/historical.sh start</span><br><span class="line">bin/middleManager.sh start</span><br></pre></td></tr></table></figure>

<blockquote>
<p>启动 Query节点</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/broker.sh start</span><br></pre></td></tr></table></figure>

<h2 id="安装Superset"><a href="#安装Superset" class="headerlink" title="安装Superset"></a>安装Superset</h2><p>Superset是一款开源的数据探索与可视化工具，支持Druid数据源，可以将druid中的数据可视化的展示，还可以支持Sql查询。<br>项目地址：<a target="_blank" rel="noopener" href="https://github.com/apache/incubator-superset">https://github.com/apache/incubator-superset</a><br>安装参考：<a target="_blank" rel="noopener" href="https://superset.incubator.apache.org/installation.html">https://superset.incubator.apache.org/installation.html</a></p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><blockquote>
<p>Not enough direct memory. </p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Not enough direct memory.  Please adjust -XX:MaxDirectMemorySize, druid.processing.buffer.sizeBytes, druid.processing.numThreads, or druid.processing.numMergeBuffers: maxDirectMemory[1,073,741,824], memoryNeeded[6,979,321,856] = druid.processing.buffer.sizeBytes[536,870,912] * (druid.processing.numMergeBuffers[2] + druid.processing.numThreads[10] + 1)</span><br></pre></td></tr></table></figure>

<p>修改-XX:MaxDirectMemorySize，使得：MaxDirectMemorySiz &gt;&#x3D; druid.processing.buffer.sizeBytes * (druid.processing.numMergeBuffers + druid.processing.numThreads + 1)</p>
<blockquote>
<p>Failed to create directory within 10000 attempts</p>
</blockquote>
<p>手动创建var&#x2F;tmp目录，路径错误，在druid中有一个环境路径需要提前手工创建environment:java.io.tmpdir&#x3D;var&#x2F;tmp</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">java.lang.IllegalStateException: Failed to create directory within 10000 attempts (tried 1538122986466-0 to 1538122986466-9999)</span><br><span class="line">	at com.google.common.io.Files.createTempDir(Files.java:600) ~[guava-16.0.1.jar:?]</span><br><span class="line">	at io.druid.segment.indexing.RealtimeTuningConfig.createNewBasePersistDirectory(RealtimeTuningConfig.java:58) ~[druid-server-0.12.3.jar:0.12.3]</span><br><span class="line">	at io.druid.segment.indexing.RealtimeTuningConfig.makeDefaultTuningConfig(RealtimeTuningConfig.java:68) ~[druid-server-0.12.3.jar:0.12.3]</span><br><span class="line">	at io.druid.segment.realtime.FireDepartment.&lt;init&gt;(FireDepartment.java:62) ~[druid-server-0.12.3.jar:0.12.3]</span><br><span class="line">	at io.druid.indexing.kafka.KafkaIndexTask.run(KafkaIndexTask.java:397) ~[?:?]</span><br><span class="line">	at io.druid.indexing.overlord.ThreadPoolTaskRunner$ThreadPoolTaskRunnerCallable.call(ThreadPoolTaskRunner.java:444) [druid-indexing-service-0.12.3.jar:0.12.3]</span><br><span class="line">	at io.druid.indexing.overlord.ThreadPoolTaskRunner$ThreadPoolTaskRunnerCallable.call(ThreadPoolTaskRunner.java:416) [druid-indexing-service-0.12.3.jar:0.12.3]</span><br><span class="line">	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_131]</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]</span><br><span class="line">	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wforget.github.io/2018/09/26/Druid%E6%9E%84%E6%9E%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wForget's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/26/Druid%E6%9E%84%E6%9E%B6/" itemprop="url">Druid构架</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-26T13:24:39+08:00">
                2018-09-26
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Druid系统架构"><a href="#Druid系统架构" class="headerlink" title="Druid系统架构"></a>Druid系统架构</h2><img src="/2018/09/26/Druid%E6%9E%84%E6%9E%B6/Druid%E6%9E%84%E6%9E%B6.png" class="" title="[Druid构架图]">

<blockquote>
<p>Historical</p>
</blockquote>
<p>历史节点对历史数据进行存储和查询，从Deep Storage下载Segment，然后响应Broker对于Segment的查询将查询结果返回给Broker节点，通过Zookeeper来声明自己存储的节点，同时也通过zookeeper来监听加载或删除Segment的信号，不接受写入操作。</p>
<blockquote>
<p>MiddleManager</p>
</blockquote>
<p>MiddleManager节点摄入新的数据到集群中，从外部数据源中读取数据并生成新的Segment。</p>
<blockquote>
<p>Broker</p>
</blockquote>
<p>Broker节点从外部客户端接收查询，并将这些查询转发给Historicals和MiddleManagers。当Brokers收到返回的结果时，它会合并这些结果并将它们返回给调用者。Druid的查询时通过请求Broker节点，而不是直接查询Historicals或MiddleManagers。</p>
<blockquote>
<p>Coordinator</p>
</blockquote>
<p>协调节点负责监控历史节点，将Segment分配给特定服务器，确保Segment在历史节点之间保持平衡。</p>
<blockquote>
<p>Overlord</p>
</blockquote>
<p>Overlord节点负责监控MiddleManager节点并控制数据摄入到Druid中。它将摄入数据的任务分配给MiddleManager节点，并协调Segment的发布。</p>
<blockquote>
<p>Router</p>
</blockquote>
<p>Router是一个可选的进程，在Brokers、Overlords和Coordinators前提供统一的网关。</p>
<h2 id="外部依赖"><a href="#外部依赖" class="headerlink" title="外部依赖"></a>外部依赖</h2><blockquote>
<p>Deep storage</p>
</blockquote>
<p>Druid使用它来存储已被摄入系统的任何数据。通常是分布式存储系统，如S3、HDFS 或 a network mounted filesystem。</p>
<blockquote>
<p>Metadata store</p>
</blockquote>
<p>存储元数据，通常是传统的关系数据库，如：PostgreSQL、MySQL。</p>
<blockquote>
<p>ZooKeeper</p>
</blockquote>
<p>ZooKeeper用于内部服务发现，协调和领导者选举。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wforget.github.io/2018/09/26/HBase-MapReduce%E7%AE%80%E5%8D%95%E5%AE%9E%E4%BE%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wForget's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/26/HBase-MapReduce%E7%AE%80%E5%8D%95%E5%AE%9E%E4%BE%8B/" itemprop="url">HBase MapReduce简单实例</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-26T12:39:51+08:00">
                2018-09-26
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="HBase-MapReduce简单实例"><a href="#HBase-MapReduce简单实例" class="headerlink" title="HBase MapReduce简单实例"></a>HBase MapReduce简单实例</h2><blockquote>
<p>前言</p>
</blockquote>
<p>在项目中使用到了HBase的MapReduce，写个小例子统计HBase table记录数</p>
<blockquote>
<p>Mapper</p>
</blockquote>
<p>需要继承 org.apache.hadoop.hbase.mapreduce.TableMapper 这个Mapper类，重写 map() 方法。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public class CounterMapper extends TableMapper&lt;Text, LongWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    protected void map(ImmutableBytesWritable key, Result value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">        String tableName = context.getConfiguration().get(TableInputFormat.INPUT_TABLE);</span><br><span class="line">        context.write(new Text(tableName), new LongWritable(1));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Reducer</p>
</blockquote>
<p>继承 org.apache.hadoop.mapreduce.Reducer 类，重写 reduce() 方法。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public class CounterReducer extends Reducer&lt;Text, LongWritable, Text, LongWritable&gt; &#123;</span><br><span class="line">    private static AtomicLong result = new AtomicLong(0);</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    protected void reduce(Text key, Iterable&lt;LongWritable&gt; values, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">        long count = 0;</span><br><span class="line">        for (LongWritable value : values) &#123;</span><br><span class="line">            count += value.get();</span><br><span class="line">        &#125;</span><br><span class="line">        result.addAndGet(count);</span><br><span class="line">        String tableName = context.getConfiguration().get(TableInputFormat.INPUT_TABLE);</span><br><span class="line">        context.write(new Text(tableName), new LongWritable(result.get()));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>job</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">public class CounterJob &#123;</span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        Configuration config = HBaseConfiguration.create();</span><br><span class="line"></span><br><span class="line">        GenericOptionsParser optionsParser = new GenericOptionsParser(config, args);</span><br><span class="line">        String[] remainingArgs = optionsParser.getRemainingArgs();</span><br><span class="line">        if (remainingArgs.length != 2) &#123;</span><br><span class="line">            System.err.println(&quot;Usage: CounterJob &lt;tableName&gt; &lt;outPath&gt;&quot;);</span><br><span class="line">            System.exit(2);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        String tableName = remainingArgs[0];</span><br><span class="line">        String outpath = remainingArgs[1];</span><br><span class="line"></span><br><span class="line">        Scan scan = new Scan();</span><br><span class="line">        scan.setCaching(500);</span><br><span class="line">        scan.setCacheBlocks(false);</span><br><span class="line"></span><br><span class="line">        Job job = Job.getInstance(config, &quot;HbaseCounterJob&quot;);</span><br><span class="line">        job.setJarByClass(CounterJob.class);</span><br><span class="line"></span><br><span class="line">        TableMapReduceUtil.initTableMapperJob(tableName, scan, CounterMapper.class, Text.class, LongWritable.class, job);</span><br><span class="line">        job.setReducerClass(CounterReducer.class);</span><br><span class="line">        job.setNumReduceTasks(1);</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(LongWritable.class);</span><br><span class="line">        FileOutputFormat.setOutputPath(job, new Path(outpath));</span><br><span class="line"></span><br><span class="line">        boolean b = job.waitForCompletion(true);</span><br><span class="line">        if (!b) &#123;</span><br><span class="line">            throw new IOException(&quot;error with job!&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wforget.github.io/2018/09/25/%E3%80%8AFlume%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0%E3%80%8B-%E4%BA%94%E3%80%81Flume%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BFlume-Channel/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wForget's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/25/%E3%80%8AFlume%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0%E3%80%8B-%E4%BA%94%E3%80%81Flume%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BFlume-Channel/" itemprop="url">《Flume系列文章》 五、Flume源码分析之Flume-Channel</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-25T17:50:10+08:00">
                2018-09-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Flume-Channel"><a href="#Flume-Channel" class="headerlink" title="Flume Channel"></a>Flume Channel</h2><p>AbstractConfigurationProvider的loadChannels()方法，加载配置文件中Channel的配置。loadChannels()中调用getOrCreateChannel()方法，通过DefaultChannelFactory.create()根据type创建不同的Channel。Flume目前实现的Channel有：Memory Channel、JDBC Channel、Kafka Channel、File Channel、Spillable Memory Channel(events存储在内存或磁盘上(溢出的时候)，试验阶段不建议生成环境使用)，具体配置参考：<a target="_blank" rel="noopener" href="http://flume.apache.org/FlumeUserGuide.html#flume-channels">http://flume.apache.org/FlumeUserGuide.html#flume-channels</a>。</p>
<h2 id="Memory-Channel"><a href="#Memory-Channel" class="headerlink" title="Memory Channel"></a>Memory Channel</h2><p>这里具体对Memory Channel源码进行分析，学习一下Channel中事务机制的实现。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">private Object queueLock = new Object();		//用于锁定queue</span><br><span class="line">@GuardedBy(value = &quot;queueLock&quot;)</span><br><span class="line">private LinkedBlockingDeque&lt;Event&gt; queue;		//Channel中存放events的队列</span><br><span class="line"></span><br><span class="line">private Semaphore queueStored;	//用于控制put和take操作的信号量，初始值为0，put操作release添加许可证，take操作tryAcquire请求许可证</span><br><span class="line"></span><br><span class="line">private Semaphore queueRemaining;	//用于控制Channel中最大event数的信号量，初始值为capacity配置。</span><br><span class="line"></span><br><span class="line">private Semaphore bytesRemaining;	//用于控制Channel中最大字节数的信号量，初始值为byteCapacity配置。</span><br></pre></td></tr></table></figure>

<blockquote>
<p>MemoryTransaction</p>
</blockquote>
<p>前面的文章中可以知道，Source是通过ChannelProcessor.processEventBatch()向Channel中put events，Sink在process()中从Channel中take events。Channel对Event具体的操作是通过MemoryTransaction实现的，MemoryTransaction中定义了两个LinkedBlockingDeque(阻塞双端队列)，takeList和putList，用来缓存一次事务中take或者put操作的events。putByteCounter和takeByteCounter对象是对events的bytes计数。<br>Channel事务中定义了put、take、commit、rollback四个操作。具体的实现：<br>put操作把event put到putList中；<br>take操作从queue中take event到takeList中，并返回event；<br>commit操作将putList里面events put到queue中，并清空takeList；<br>rollback操作是将takeList里面的events put回queue中，并清空putList。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line">private class MemoryTransaction extends BasicTransactionSemantics &#123;</span><br><span class="line">  private LinkedBlockingDeque&lt;Event&gt; takeList;  //存放take操作的events</span><br><span class="line">  private LinkedBlockingDeque&lt;Event&gt; putList;   //存放put操作的events</span><br><span class="line">  private final ChannelCounter channelCounter;  //channel counter（监控）</span><br><span class="line">  private int putByteCounter = 0;   //put events的总bytes</span><br><span class="line">  private int takeByteCounter = 0;  //take events的总bytes</span><br><span class="line"></span><br><span class="line">  public MemoryTransaction(int transCapacity, ChannelCounter counter) &#123;</span><br><span class="line">    //transCapacity 是一次事务中操作events的最大数量</span><br><span class="line">    putList = new LinkedBlockingDeque&lt;Event&gt;(transCapacity);</span><br><span class="line">    takeList = new LinkedBlockingDeque&lt;Event&gt;(transCapacity);</span><br><span class="line"></span><br><span class="line">    channelCounter = counter;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  //put操作是把event put到putList中</span><br><span class="line">  @Override</span><br><span class="line">  protected void doPut(Event event) throws InterruptedException &#123;</span><br><span class="line">    channelCounter.incrementEventPutAttemptCount();</span><br><span class="line">    int eventByteSize = (int) Math.ceil(estimateEventSize(event) / byteCapacitySlotSize);</span><br><span class="line"></span><br><span class="line">    if (!putList.offer(event)) &#123;  //向putList中offer event，满了的话抛出异常</span><br><span class="line">      throw new ChannelException(</span><br><span class="line">          &quot;Put queue for MemoryTransaction of capacity &quot; +</span><br><span class="line">          putList.size() + &quot; full, consider committing more frequently, &quot; +</span><br><span class="line">          &quot;increasing capacity or increasing thread count&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    putByteCounter += eventByteSize;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  //take操作是从channel 的 events queue中take event到takeList中</span><br><span class="line">  @Override</span><br><span class="line">  protected Event doTake() throws InterruptedException &#123;</span><br><span class="line">    channelCounter.incrementEventTakeAttemptCount();</span><br><span class="line">    if (takeList.remainingCapacity() == 0) &#123;  //takeList满了的话抛出异常</span><br><span class="line">      throw new ChannelException(&quot;Take list for MemoryTransaction, capacity &quot; +</span><br><span class="line">          takeList.size() + &quot; full, consider committing more frequently, &quot; +</span><br><span class="line">          &quot;increasing capacity, or increasing thread count&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    if (!queueStored.tryAcquire(keepAlive, TimeUnit.SECONDS)) &#123;   //请求许可</span><br><span class="line">      return null;</span><br><span class="line">    &#125;</span><br><span class="line">    Event event;</span><br><span class="line">    synchronized (queueLock) &#123;  //锁定queue，poll一个event</span><br><span class="line">      event = queue.poll();</span><br><span class="line">    &#125;</span><br><span class="line">    Preconditions.checkNotNull(event, &quot;Queue.poll returned NULL despite semaphore &quot; +</span><br><span class="line">        &quot;signalling existence of entry&quot;);</span><br><span class="line">    takeList.put(event);  //将event存入takeList</span><br><span class="line"></span><br><span class="line">    int eventByteSize = (int) Math.ceil(estimateEventSize(event) / byteCapacitySlotSize);</span><br><span class="line">    takeByteCounter += eventByteSize;</span><br><span class="line"></span><br><span class="line">    return event;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  //commit操作是将putList里面events put到queue中，并清空takeList</span><br><span class="line">  @Override</span><br><span class="line">  protected void doCommit() throws InterruptedException &#123;</span><br><span class="line">    int remainingChange = takeList.size() - putList.size();</span><br><span class="line">    if (remainingChange &lt; 0) &#123;</span><br><span class="line">      //判断put到queue中是否会导致，channel中最大字节数操作byteCapacity</span><br><span class="line">      if (!bytesRemaining.tryAcquire(putByteCounter, keepAlive, TimeUnit.SECONDS)) &#123;</span><br><span class="line">        throw new ChannelException(&quot;Cannot commit transaction. Byte capacity &quot; +</span><br><span class="line">            &quot;allocated to store event body &quot; + byteCapacity * byteCapacitySlotSize +</span><br><span class="line">            &quot;reached. Please increase heap space/byte capacity allocated to &quot; +</span><br><span class="line">            &quot;the channel as the sinks may not be keeping up with the sources&quot;);</span><br><span class="line">      &#125;</span><br><span class="line">      //判断提交本次事务是否会导致channel中的events的数量超过capacity</span><br><span class="line">      if (!queueRemaining.tryAcquire(-remainingChange, keepAlive, TimeUnit.SECONDS)) &#123;</span><br><span class="line">        bytesRemaining.release(putByteCounter);</span><br><span class="line">        throw new ChannelFullException(&quot;Space for commit to queue couldn&#x27;t be acquired.&quot; +</span><br><span class="line">            &quot; Sinks are likely not keeping up with sources, or the buffer size is too tight&quot;);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    int puts = putList.size();</span><br><span class="line">    int takes = takeList.size();</span><br><span class="line">    synchronized (queueLock) &#123;  //将putList里面events put到queue中，并清空takeList</span><br><span class="line">      if (puts &gt; 0) &#123;</span><br><span class="line">        while (!putList.isEmpty()) &#123;</span><br><span class="line">          if (!queue.offer(putList.removeFirst())) &#123;</span><br><span class="line">            throw new RuntimeException(&quot;Queue add failed, this shouldn&#x27;t be able to happen&quot;);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      putList.clear();</span><br><span class="line">      takeList.clear();</span><br><span class="line">    &#125;</span><br><span class="line">    bytesRemaining.release(takeByteCounter);</span><br><span class="line">    takeByteCounter = 0;</span><br><span class="line">    putByteCounter = 0;</span><br><span class="line"></span><br><span class="line">    queueStored.release(puts);</span><br><span class="line">    if (remainingChange &gt; 0) &#123;</span><br><span class="line">      queueRemaining.release(remainingChange);</span><br><span class="line">    &#125;</span><br><span class="line">    if (puts &gt; 0) &#123;</span><br><span class="line">      channelCounter.addToEventPutSuccessCount(puts);</span><br><span class="line">    &#125;</span><br><span class="line">    if (takes &gt; 0) &#123;</span><br><span class="line">      channelCounter.addToEventTakeSuccessCount(takes);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    channelCounter.setChannelSize(queue.size());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  //rollback操作是将takeList里面的events put回queue中，并清空putList</span><br><span class="line">  @Override</span><br><span class="line">  protected void doRollback() &#123;</span><br><span class="line">    int takes = takeList.size();</span><br><span class="line">    synchronized (queueLock) &#123;</span><br><span class="line">      Preconditions.checkState(queue.remainingCapacity() &gt;= takeList.size(),</span><br><span class="line">          &quot;Not enough space in memory channel &quot; +</span><br><span class="line">          &quot;queue to rollback takes. This should never happen, please report&quot;);</span><br><span class="line">      while (!takeList.isEmpty()) &#123;</span><br><span class="line">        queue.addFirst(takeList.removeLast());</span><br><span class="line">      &#125;</span><br><span class="line">      putList.clear();</span><br><span class="line">    &#125;</span><br><span class="line">    putByteCounter = 0;</span><br><span class="line">    takeByteCounter = 0;</span><br><span class="line"></span><br><span class="line">    queueStored.release(takes);</span><br><span class="line">    channelCounter.setChannelSize(queue.size());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/">&lt;i class&#x3D;&quot;fa fa-angle-left&quot;&gt;&lt;&#x2F;i&gt;</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/5/">&lt;i class&#x3D;&quot;fa fa-angle-right&quot;&gt;&lt;&#x2F;i&gt;</a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">44</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">27</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/wForget" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wangz</span>

  
</div>









        







  <div style="display: none;">
    <script src="//s23.cnzz.com/z_stat.php?id=1276876819&web_id=1276876819" language="JavaScript"></script>
  </div>



        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  













  





  

  

  

  
  

  

  

  

</body>
</html>
